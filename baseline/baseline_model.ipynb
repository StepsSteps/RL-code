{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import baseline_methods as bm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 27468, 2)\n"
     ]
    }
   ],
   "source": [
    "# cn_delay = np.load('./cdata/China.npz')\n",
    "# cn_delay = cn_delay['data']\n",
    "# cn_delay = cn_delay.transpose(1,0,2)\n",
    "cn_delay = np.load('./cdata/delay.npy')\n",
    "print(cn_delay.shape)\n",
    "# Shape(N, T, F)\n",
    "\n",
    "# cn_delay_1 arrival delay\n",
    "cn_delay_1 = cn_delay[:, :, 0]\n",
    "# cn_delay_1 departure delay\n",
    "cn_delay_2 = cn_delay[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 27468)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_delay_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 78912, 2)\n",
      "(70, 78912)\n"
     ]
    }
   ],
   "source": [
    "us_delay = np.load('./udata/udelay.npy')\n",
    "print(us_delay.shape)\n",
    "# Shape(N, T, F)\n",
    "\n",
    "# us_delay_1 arrival delay\n",
    "us_delay_1 = us_delay[:, :, 0]\n",
    "# us_delay_1 departure delay\n",
    "us_delay_2 = us_delay[:, :, 1]\n",
    "\n",
    "print(us_delay_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error for arrival prediction delay using HA is (9.089, 11.847, 1.149)\n",
      "The test error for delay prediction delay using HA is (6.519, 8.631, 1.284)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuzheyang/Library/Mobile Documents/3L68KQB4HG~com~readdle~CommonDocuments/Documents/CUHKSZ/Research Learning/RL-code/baseline/baseline_methods.py:73: RuntimeWarning: Mean of empty slice.\n",
      "  y_predict[k, i - n_train] = historical[k, :][~np.isnan(historical[k, :])].mean()\n",
      "/Users/yuzheyang/anaconda3/envs/torch_env/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# y_predict, y_test = bm.historical_average_predict(\n",
    "#     cn_delay_1, period=2*18, test_ratio=0.2)\n",
    "# ha_a_mae, ha_a_rmse, ha_a_mape = bm.test_error(y_predict, y_test)\n",
    "# y_predict, y_test = bm.historical_average_predict(\n",
    "#     cn_delay_2, period=2*18, test_ratio=0.2)\n",
    "\n",
    "y_predict, y_test = bm.historical_average_predict(\n",
    "    us_delay_1, period=2*18, test_ratio=0.2)\n",
    "ha_a_mae, ha_a_rmse, ha_a_mape = bm.test_error(y_predict, y_test)\n",
    "y_predict, y_test = bm.historical_average_predict(\n",
    "    us_delay_2, period=2*18, test_ratio=0.2)\n",
    "ha_d_mae, ha_d_rmse, ha_d_mape = bm.test_error(y_predict, y_test)\n",
    "print(\n",
    "    f\"The test error for arrival prediction delay using HA is {round(ha_a_mae,3), round(ha_a_rmse,3), round(ha_a_mape,3)}\")\n",
    "print(\n",
    "    f\"The test error for delay prediction delay using HA is {round(ha_d_mae,3), round(ha_d_rmse,3), round(ha_d_mape,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = [2, 5, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of VAR in 3-step arrival: (7.795, 10.468, 1.211)\n",
      "Error of VAR in 6-step arrival: (8.123, 10.824, 1.224)\n",
      "Error of VAR in 12-step arrival: (8.479, 11.237, 1.216)\n",
      "Error of VAR in 3-step departure: (5.561, 7.656, 1.129)\n",
      "Error of VAR in 6-step departure: (5.817, 7.925, 1.14)\n",
      "Error of VAR in 12-step departure: (6.165, 8.304, 1.129)\n"
     ]
    }
   ],
   "source": [
    "# y_predict_a, y_test_a = bm.var_predict(cn_delay_1, test_ratio=0.2)\n",
    "# y_predict_d, y_test_d = bm.var_predict(cn_delay_2, test_ratio=0.2)\n",
    "y_predict_a, y_test_a = bm.var_predict(us_delay_1, test_ratio=0.2)\n",
    "y_predict_d, y_test_d = bm.var_predict(us_delay_2, test_ratio=0.2)\n",
    "var_a_mae = []\n",
    "var_a_rmse = []\n",
    "var_a_mape = []\n",
    "var_d_mae = []\n",
    "var_d_rmse = []\n",
    "var_d_mape = []\n",
    "for i in time:\n",
    "    a, b, c = bm.test_error(y_predict_a[i, :, :].T, y_test_a)\n",
    "    var_a_mae.append(round(a, 3))\n",
    "    var_a_rmse.append(round(b, 3))\n",
    "    var_a_mape.append(round(c, 3))\n",
    "    a, b, c = bm.test_error(y_predict_d[i, :, :].T, y_test_d)\n",
    "    var_d_mae.append(round(a, 3))\n",
    "    var_d_rmse.append(round(b, 3))\n",
    "    var_d_mape.append(round(c, 3))\n",
    "\n",
    "for i, x in enumerate(zip(var_a_mae, var_a_rmse, var_a_mape)):\n",
    "    print(f\"Error of VAR in {time[i]+1}-step arrival: {x}\")\n",
    "\n",
    "for i, x in enumerate(zip(var_d_mae, var_d_rmse, var_d_mape)):\n",
    "    print(f\"Error of VAR in {time[i]+1}-step departure: {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predict_a, y_test_a = bm.arima_predict(cn_delay_1, test_ratio=0.02)\n",
    "# y_predict_d, y_test_d = bm.arima_predict(cn_delay_2, test_ratio=0.02)\n",
    "\n",
    "y_predict_a, y_test_a = bm.arima_predict(us_delay_1, test_ratio=0.02)\n",
    "y_predict_d, y_test_d = bm.arima_predict(us_delay_2, test_ratio=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(12, 1578, 70)\n",
      "(70, 1578)\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(np.isnan(y_predict_a)))\n",
    "print(y_predict_a.shape)\n",
    "print(y_test_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of ARIMA in 3-step arrival: (10.508, 13.894, 2.436)\n",
      "Error of ARIMA in 6-step arrival: (10.481, 13.863, 2.419)\n",
      "Error of ARIMA in 12-step arrival: (10.599, 14.02, 2.48)\n",
      "Error of ARIMA in 3-step departure: (7.607, 10.549, 1.133)\n",
      "Error of ARIMA in 6-step departure: (7.587, 10.551, 1.123)\n",
      "Error of ARIMA in 12-step departure: (7.653, 10.643, 1.142)\n"
     ]
    }
   ],
   "source": [
    "arima_a_mae = []\n",
    "arima_a_rmse = []\n",
    "arima_a_mape = []\n",
    "arima_d_mae = []\n",
    "arima_d_rmse = []\n",
    "arima_d_mape = []\n",
    "for i in time:\n",
    "    a, b, c = bm.test_error(y_predict_a[i, :, :].T, y_test_a)\n",
    "    arima_a_mae.append(round(a, 3))\n",
    "    arima_a_rmse.append(round(b, 3))\n",
    "    arima_a_mape.append(round(c, 3))\n",
    "    a, b, c = bm.test_error(y_predict_d[i, :, :].T, y_test_d)\n",
    "    arima_d_mae.append(round(a, 3))\n",
    "    arima_d_rmse.append(round(b, 3))\n",
    "    arima_d_mape.append(round(c, 3))\n",
    "\n",
    "for i, x in enumerate(zip(arima_a_mae, arima_a_rmse, arima_a_mape)):\n",
    "    print(f\"Error of ARIMA in {time[i]+1}-step arrival: {x}\")\n",
    "\n",
    "for i, x in enumerate(zip(arima_d_mae, arima_d_rmse, arima_d_mape)):\n",
    "    print(f\"Error of ARIMA in {time[i]+1}-step departure: {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/70 [32:59<37:56:38, 1979.68s/it]/Users/yuzheyang/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "  3%|▎         | 2/70 [1:18:10<45:30:51, 2409.59s/it]/Users/yuzheyang/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "  4%|▍         | 3/70 [2:01:03<46:14:18, 2484.45s/it]/Users/yuzheyang/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "  6%|▌         | 4/70 [2:46:59<47:30:37, 2591.47s/it]/Users/yuzheyang/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "  7%|▋         | 5/70 [3:30:28<46:54:26, 2597.95s/it]/Users/yuzheyang/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "  9%|▊         | 6/70 [4:16:27<47:09:35, 2652.75s/it]/Users/yuzheyang/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      " 10%|█         | 7/70 [5:08:24<49:04:29, 2804.28s/it]/Users/yuzheyang/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      " 11%|█▏        | 8/70 [6:00:19<50:00:06, 2903.33s/it]/Users/yuzheyang/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      " 13%|█▎        | 9/70 [6:45:28<48:10:00, 2842.63s/it]/Users/yuzheyang/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      " 14%|█▍        | 10/70 [7:37:22<48:46:22, 2926.37s/it]/Users/yuzheyang/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      " 16%|█▌        | 11/70 [8:29:36<49:00:08, 2989.97s/it]/Users/yuzheyang/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      " 17%|█▋        | 12/70 [9:20:06<48:21:59, 3002.05s/it]/Users/yuzheyang/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      " 19%|█▊        | 13/70 [10:13:47<48:34:58, 3068.39s/it]/Users/yuzheyang/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      " 20%|██        | 14/70 [11:29:50<45:59:20, 2956.43s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# y_predict_a, y_test_a = bm.var_predict_svr(cn_delay_1, test_ratio=0.2)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# y_predict_d, y_test_d = bm.var_predict_svr(cn_delay_2, test_ratio=0.2)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m y_predict_a, y_test_a \u001b[39m=\u001b[39m bm\u001b[39m.\u001b[39;49mvar_predict_svr(us_delay_1, test_ratio\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m y_predict_d, y_test_d \u001b[39m=\u001b[39m bm\u001b[39m.\u001b[39mvar_predict_svr(us_delay_2, test_ratio\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[1;32m      5\u001b[0m np\u001b[39m.\u001b[39msavez(\u001b[39m\"\u001b[39m\u001b[39mtmp_svr.npz\u001b[39m\u001b[39m\"\u001b[39m, y_predict_a\u001b[39m=\u001b[39my_predict_a, y_test_a\u001b[39m=\u001b[39my_test_a,\n\u001b[1;32m      6\u001b[0m          y_predict_d\u001b[39m=\u001b[39my_predict_d, y_test_d\u001b[39m=\u001b[39my_test_d)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/3L68KQB4HG~com~readdle~CommonDocuments/Documents/CUHKSZ/Research Learning/RL-code/baseline/baseline_methods.py:185\u001b[0m, in \u001b[0;36mvar_predict_svr\u001b[0;34m(np_, out_len, in_len, test_ratio, kernel, C, epsilon)\u001b[0m\n\u001b[1;32m    183\u001b[0m X_train, Y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(X_train), np\u001b[39m.\u001b[39marray(Y_train)\n\u001b[1;32m    184\u001b[0m svr_model \u001b[39m=\u001b[39m MultiOutputRegressor(SVR(kernel\u001b[39m=\u001b[39mkernel),n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 185\u001b[0m svr_model\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[1;32m    186\u001b[0m \u001b[39m#print(f\"Fit OK in {route}!\")\u001b[39;00m\n\u001b[1;32m    187\u001b[0m X_test, Y_test \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.11/site-packages/sklearn/multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnderlying estimator does not support sample weights.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    214\u001b[0m fit_params_validated \u001b[39m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[0;32m--> 216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    217\u001b[0m     delayed(_fit_estimator)(\n\u001b[1;32m    218\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y[:, i], sample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_validated\n\u001b[1;32m    219\u001b[0m     )\n\u001b[1;32m    220\u001b[0m     \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(y\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    221\u001b[0m )\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mn_features_in_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    224\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_features_in_\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# y_predict_a, y_test_a = bm.var_predict_svr(cn_delay_1, test_ratio=0.2)\n",
    "# y_predict_d, y_test_d = bm.var_predict_svr(cn_delay_2, test_ratio=0.2)\n",
    "y_predict_a, y_test_a = bm.var_predict_svr(us_delay_1, test_ratio=0.2)\n",
    "y_predict_d, y_test_d = bm.var_predict_svr(us_delay_2, test_ratio=0.2)\n",
    "np.savez(\"tmp_svr.npz\", y_predict_a=y_predict_a, y_test_a=y_test_a,\n",
    "         y_predict_d=y_predict_d, y_test_d=y_test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_a = y_test_a[:-36]\n",
    "time = [2, 5, 11]\n",
    "out_len = 12\n",
    "var_a_mae = []\n",
    "var_a_rmse = []\n",
    "var_a_mape = []\n",
    "var_d_mae = []\n",
    "var_d_rmse = []\n",
    "var_d_mape = []\n",
    "\n",
    "for i in time:\n",
    "    shift = i+1\n",
    "    num_sample = y_test_a.shape[-1]\n",
    "    a, b, c = bm.test_error(\n",
    "        y_predict_a[:, :, i], y_test_a[:, shift:num_sample-(out_len-shift)])\n",
    "    # y_predict_a: [T, N]  y_test_a: [T, N], shift `i+1` slots\n",
    "    var_a_mae.append(round(a, 3))\n",
    "    var_a_rmse.append(round(b, 3))\n",
    "    var_a_mape.append(round(c, 3))\n",
    "    a, b, c = bm.test_error(\n",
    "        y_predict_d[:, :, i], y_test_d[:, shift:num_sample-(out_len-shift)])\n",
    "    # y_predict_a: [T, N]  y_test_a: [T, N], shift `i+1` slots\n",
    "    var_d_mae.append(round(a, 3))\n",
    "    var_d_rmse.append(round(b, 3))\n",
    "    var_d_mape.append(round(c, 3))\n",
    "\n",
    "for i, x in enumerate(zip(var_a_mae, var_a_rmse, var_a_mape)):\n",
    "    print(f\"Error of SVM in {(time[i]+1)}-step arrival: {x}\")\n",
    "\n",
    "for i, x in enumerate(zip(var_d_mae, var_d_rmse, var_d_mape)):\n",
    "    print(f\"Error of SVM in {(time[i]+1)}-step departure: {x}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
